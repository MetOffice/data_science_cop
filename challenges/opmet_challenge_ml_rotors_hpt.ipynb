{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-spine",
   "metadata": {},
   "source": [
    "# OpMet Challenge 2021: Falkland Rotors - Hyperparameter Tuning in sklearn\n",
    "\n",
    "Following on from the previous basic ML using scikit-learn notebook, we now proceed to using hyperparameter tuning to select the best hyperparameters for our three model types from sklearn (decision tree, random forest and neural network)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-chicken",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "In this notebook, in addition to the standard python auxillary libraries, we are using the following:\n",
    "* matplotlib - plotting \n",
    "* pandas - loading tabular data\n",
    "* scikit learn - machine learning\n",
    "\n",
    "This has been tested with the conda environment based on the requirements.yaml file in this repository, as well as the `scitools/experimental-current` Met Office managed conda environement (August 20201)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exotic-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime\n",
    "import math\n",
    "import functools\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finnish-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "printable-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finished-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confident-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.preprocessing\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_data_dir = '/data/users/shaddad/ds_cop/2021_opmet_challenge/ML'\n",
    "root_data_dir = '/project/informatics_lab/data_science_cop/ML_challenges/2021_opmet_challenge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-smith",
   "metadata": {},
   "source": [
    "## Exploring Falklands Rotor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "falklands_dir = 'Rotors'\n",
    "falklands_data_path = pathlib.Path(root_data_dir, falklands_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "answering-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "falklands_new_training_data_path = pathlib.Path(falklands_data_path, 'new_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colored-group",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTG</th>\n",
       "      <th>air_temp_obs</th>\n",
       "      <th>dewpoint_obs</th>\n",
       "      <th>wind_direction_obs</th>\n",
       "      <th>wind_speed_obs</th>\n",
       "      <th>wind_gust_obs</th>\n",
       "      <th>air_temp_1</th>\n",
       "      <th>air_temp_2</th>\n",
       "      <th>air_temp_3</th>\n",
       "      <th>air_temp_4</th>\n",
       "      <th>...</th>\n",
       "      <th>windspd_18</th>\n",
       "      <th>winddir_19</th>\n",
       "      <th>windspd_19</th>\n",
       "      <th>winddir_20</th>\n",
       "      <th>windspd_20</th>\n",
       "      <th>winddir_21</th>\n",
       "      <th>windspd_21</th>\n",
       "      <th>winddir_22</th>\n",
       "      <th>windspd_22</th>\n",
       "      <th>Rotors 1 is true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2015 00:00</td>\n",
       "      <td>283.9</td>\n",
       "      <td>280.7</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.000</td>\n",
       "      <td>283.625</td>\n",
       "      <td>283.250</td>\n",
       "      <td>282.625</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>341.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>330.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2015 03:00</td>\n",
       "      <td>280.7</td>\n",
       "      <td>279.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>281.500</td>\n",
       "      <td>281.250</td>\n",
       "      <td>280.750</td>\n",
       "      <td>280.250</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>344.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>348.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2015 06:00</td>\n",
       "      <td>279.8</td>\n",
       "      <td>278.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.875</td>\n",
       "      <td>279.625</td>\n",
       "      <td>279.125</td>\n",
       "      <td>278.625</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>358.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2015 09:00</td>\n",
       "      <td>279.9</td>\n",
       "      <td>277.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.625</td>\n",
       "      <td>279.250</td>\n",
       "      <td>278.875</td>\n",
       "      <td>278.250</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/01/2015 12:00</td>\n",
       "      <td>279.9</td>\n",
       "      <td>277.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.250</td>\n",
       "      <td>278.875</td>\n",
       "      <td>278.375</td>\n",
       "      <td>277.875</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>273.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>329.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20101</th>\n",
       "      <td>31/12/2020 06:00</td>\n",
       "      <td>276.7</td>\n",
       "      <td>275.5</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.750</td>\n",
       "      <td>277.625</td>\n",
       "      <td>277.500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>223.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>221.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>219.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20102</th>\n",
       "      <td>31/12/2020 09:00</td>\n",
       "      <td>277.9</td>\n",
       "      <td>276.9</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.625</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.875</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>230.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>230.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>227.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20103</th>\n",
       "      <td>31/12/2020 12:00</td>\n",
       "      <td>283.5</td>\n",
       "      <td>277.1</td>\n",
       "      <td>220.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>281.125</td>\n",
       "      <td>280.625</td>\n",
       "      <td>280.125</td>\n",
       "      <td>279.625</td>\n",
       "      <td>...</td>\n",
       "      <td>10.3</td>\n",
       "      <td>218.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20104</th>\n",
       "      <td>31/12/2020 15:00</td>\n",
       "      <td>286.1</td>\n",
       "      <td>276.9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.625</td>\n",
       "      <td>284.125</td>\n",
       "      <td>283.625</td>\n",
       "      <td>283.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>226.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20105</th>\n",
       "      <td>01/01/2021 00:00</td>\n",
       "      <td>285.1</td>\n",
       "      <td>279.3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.250</td>\n",
       "      <td>284.000</td>\n",
       "      <td>283.750</td>\n",
       "      <td>283.250</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>241.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>236.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>232.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>227.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20105 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DTG  air_temp_obs  dewpoint_obs  wind_direction_obs  \\\n",
       "1      01/01/2015 00:00         283.9         280.7               110.0   \n",
       "2      01/01/2015 03:00         280.7         279.7                90.0   \n",
       "3      01/01/2015 06:00         279.8         278.1               100.0   \n",
       "4      01/01/2015 09:00         279.9         277.0               120.0   \n",
       "5      01/01/2015 12:00         279.9         277.4               120.0   \n",
       "...                 ...           ...           ...                 ...   \n",
       "20101  31/12/2020 06:00         276.7         275.5               270.0   \n",
       "20102  31/12/2020 09:00         277.9         276.9               270.0   \n",
       "20103  31/12/2020 12:00         283.5         277.1               220.0   \n",
       "20104  31/12/2020 15:00         286.1         276.9               250.0   \n",
       "20105  01/01/2021 00:00         285.1         279.3               300.0   \n",
       "\n",
       "       wind_speed_obs  wind_gust_obs  air_temp_1  air_temp_2  air_temp_3  \\\n",
       "1                 4.1     -9999999.0     284.000     283.625     283.250   \n",
       "2                 7.7     -9999999.0     281.500     281.250     280.750   \n",
       "3                 7.7     -9999999.0     279.875     279.625     279.125   \n",
       "4                 7.2     -9999999.0     279.625     279.250     278.875   \n",
       "5                 8.7     -9999999.0     279.250     278.875     278.375   \n",
       "...               ...            ...         ...         ...         ...   \n",
       "20101             3.6     -9999999.0     277.875     277.750     277.625   \n",
       "20102             3.1     -9999999.0     277.875     277.625     277.875   \n",
       "20103             3.6     -9999999.0     281.125     280.625     280.125   \n",
       "20104             3.6     -9999999.0     284.625     284.125     283.625   \n",
       "20105             6.2     -9999999.0     284.250     284.000     283.750   \n",
       "\n",
       "       air_temp_4  ...  windspd_18  winddir_19  windspd_19  winddir_20  \\\n",
       "1         282.625  ...         5.8       341.0         6.0       334.0   \n",
       "2         280.250  ...         6.8       344.0         5.3       348.0   \n",
       "3         278.625  ...         6.0       345.0         5.5       358.0   \n",
       "4         278.250  ...         3.1       338.0         3.5       354.0   \n",
       "5         277.875  ...         1.6       273.0         2.0       303.0   \n",
       "...           ...  ...         ...         ...         ...         ...   \n",
       "20101     277.500  ...        12.1       223.0        11.8       221.0   \n",
       "20102     277.875  ...        10.2       230.0        10.8       230.0   \n",
       "20103     279.625  ...        10.3       218.0        11.9       221.0   \n",
       "20104     283.000  ...         9.4       218.0         8.6       212.0   \n",
       "20105     283.250  ...         8.6       241.0        10.2       236.0   \n",
       "\n",
       "       windspd_20  winddir_21  windspd_21  winddir_22  windspd_22  \\\n",
       "1             6.1       330.0         6.0       329.0         5.8   \n",
       "2             3.8       360.0         3.2        12.0         3.5   \n",
       "3             5.0        10.0         4.2        38.0         4.0   \n",
       "4             3.9         9.0         4.4        22.0         4.6   \n",
       "5             2.3       329.0         2.5       338.0         2.4   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "20101        11.4       219.0        11.3       215.0        11.4   \n",
       "20102        11.6       227.0        12.3       222.0        12.0   \n",
       "20103        12.8       222.0        11.9       225.0        10.6   \n",
       "20104         8.3       218.0         8.7       226.0        10.1   \n",
       "20105        10.5       232.0        10.5       227.0        11.3   \n",
       "\n",
       "       Rotors 1 is true  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "...                 ...  \n",
       "20101               NaN  \n",
       "20102               NaN  \n",
       "20103               NaN  \n",
       "20104               NaN  \n",
       "20105               NaN  \n",
       "\n",
       "[20105 rows x 95 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df = pandas.read_csv(falklands_new_training_data_path, header=0).loc[1:,:]\n",
    "falklands_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consolidated-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "falklands_training_df = falklands_training_df.drop_duplicates(subset='DTG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satellite-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17507, 95)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-advisory",
   "metadata": {},
   "source": [
    "### Specify and create input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "asian-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_feature_names = [f'air_temp_{i1}' for i1 in range(1,23)]\n",
    "humidity_feature_names = [f'sh_{i1}' for i1 in range(1,23)]\n",
    "wind_direction_feature_names = [f'winddir_{i1}' for i1 in range(1,23)]\n",
    "wind_speed_feature_names = [f'windspd_{i1}' for i1 in range(1,23)]\n",
    "target_feature_name = 'rotors_present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "serial-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_wind(wind_dir_name, wind_speed_name, row1):\n",
    "    return math.cos(math.radians(row1[wind_dir_name])) * row1[wind_speed_name]\n",
    "\n",
    "def get_u_wind(wind_dir_name, wind_speed_name, row1):\n",
    "    return math.sin(math.radians(row1[wind_dir_name])) * row1[wind_speed_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "indian-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "u_feature_template = 'u_wind_{level_ix}'\n",
    "v_feature_template = 'v_wind_{level_ix}'\n",
    "u_wind_feature_names = []\n",
    "v_wind_features_names = []\n",
    "for wsn1, wdn1 in zip(wind_speed_feature_names, wind_direction_feature_names):\n",
    "    level_ix = int( wsn1.split('_')[1])\n",
    "    u_feature = u_feature_template.format(level_ix=level_ix)\n",
    "    u_wind_feature_names += [u_feature]\n",
    "    falklands_training_df[u_feature_template.format(level_ix=level_ix)] = falklands_training_df.apply(functools.partial(get_u_wind, wdn1, wsn1), axis='columns')\n",
    "    v_feature = v_feature_template.format(level_ix=level_ix)\n",
    "    v_wind_features_names += [v_feature]\n",
    "    falklands_training_df[v_feature_template.format(level_ix=level_ix)] = falklands_training_df.apply(functools.partial(get_v_wind, wdn1, wsn1), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "irish-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "falklands_training_df[target_feature_name] =  falklands_training_df['Rotors 1 is true']\n",
    "falklands_training_df.loc[falklands_training_df[falklands_training_df['Rotors 1 is true'].isna()].index, target_feature_name] = 0.0\n",
    "falklands_training_df[target_feature_name]  = falklands_training_df[target_feature_name] .astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "friendly-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    17058\n",
       "True       449\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "secure-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DTG', 'air_temp_obs', 'dewpoint_obs', 'wind_direction_obs',\n",
       "       'wind_speed_obs', 'wind_gust_obs', 'air_temp_1', 'air_temp_2',\n",
       "       'air_temp_3', 'air_temp_4',\n",
       "       ...\n",
       "       'v_wind_18', 'u_wind_19', 'v_wind_19', 'u_wind_20', 'v_wind_20',\n",
       "       'u_wind_21', 'v_wind_21', 'u_wind_22', 'v_wind_22', 'rotors_present'],\n",
       "      dtype='object', length=140)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-objective",
   "metadata": {},
   "source": [
    "### SPlit into traing/validate/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "superb-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_name = 'test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "opposed-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.1\n",
    "validation_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "smoking-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_no_rotors = sum(falklands_training_df[target_feature_name] == False)\n",
    "num_with_rotors = sum(falklands_training_df[target_feature_name] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sitting-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_rotors = falklands_training_df[falklands_training_df[target_feature_name] == False]\n",
    "data_with_rotors = falklands_training_df[falklands_training_df[target_feature_name] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incorrect-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1705\n",
       "True       44\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pandas.concat([data_no_rotors.sample(int(test_fraction * num_no_rotors)), data_with_rotors.sample(int(test_fraction * num_with_rotors))])\n",
    "data_test[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "peripheral-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "falklands_training_df[test_set_name] = False\n",
    "falklands_training_df.loc[data_test.index,test_set_name] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "decreased-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_working = falklands_training_df[falklands_training_df[test_set_name] == False]\n",
    "data_working_no_rotors = data_working[data_working[target_feature_name] == False]\n",
    "data_working_with_rotors = data_working[data_working[target_feature_name] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-matter",
   "metadata": {},
   "source": [
    "# Preprocess data into input for ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "southern-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_names = temp_feature_names + humidity_feature_names + u_wind_feature_names + v_wind_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "persistent-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dict = {}\n",
    "for if1 in input_feature_names:\n",
    "    scaler1 = sklearn.preprocessing.StandardScaler()\n",
    "    scaler1.fit(data_working[[if1]])\n",
    "    preproc_dict[if1] = scaler1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opponent-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "target_encoder.fit(data_working[[target_feature_name]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-indie",
   "metadata": {},
   "source": [
    "Apply transformation to each input column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decimal-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_input(data_subset, pp_dict):\n",
    "    return numpy.concatenate([scaler1.transform(data_subset[[if1]]) for if1,scaler1 in pp_dict.items()],axis=1)\n",
    "\n",
    "def preproc_target(data_subset, enc1):\n",
    "     return enc1.transform(data_subset[[target_feature_name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "optional-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_working = preproc_input(data_working, preproc_dict)\n",
    "y_working = preproc_target(data_working, target_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-workplace",
   "metadata": {},
   "source": [
    "create target feature from rotors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "general-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15758,), (15758, 88))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_working.shape, X_working.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "divided-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test = preproc_input(data_test, preproc_dict)\n",
    "y_test = preproc_target(data_test, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "agreed-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_tuples = [\n",
    "    (X_working, y_working),\n",
    "    (X_test, y_test),    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-tablet",
   "metadata": {},
   "source": [
    "### train some classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "early-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_hidden_layers_specs = [(50,)*2, (50,)*4, (50,)*8, (100,)*2, (100,)*5, (100,)*8, (200,)*4, (400,)*4, (500,)*4]\n",
    "nn_hidden_layers_specs = [(50,)*2, (50,)*8, (100,)*2, (100,)*5,]\n",
    "\n",
    "classifiers_params = {\n",
    "    'decision_tree': {'class': sklearn.tree.DecisionTreeClassifier, 'opts': {'max_depth':[5,10,15,20], 'class_weight':['balanced']}},\n",
    "    'random_forest': {'class': sklearn.ensemble.RandomForestClassifier, 'opts': {'max_depth':[5,10,15,20], 'class_weight':['balanced']}},\n",
    "     'ann': {'class': sklearn.neural_network.MLPClassifier, 'opts': {'hidden_layer_sizes': nn_hidden_layers_specs}},   \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distinct-fellowship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n",
      "random_forest\n",
      "ann\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 25s, sys: 59.8 s, total: 30min 24s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifiers_dict = {}             \n",
    "for clf_name, clf_params in classifiers_params.items():\n",
    "    print(clf_name)\n",
    "    clf1 = clf_params['class']()\n",
    "    cv1 = sklearn.model_selection.KFold(n_splits=5, shuffle=True)\n",
    "    hpt1 = sklearn.model_selection.GridSearchCV(clf1, \n",
    "                                                clf_params['opts'],\n",
    "                                                cv=cv1,\n",
    "                                               )\n",
    "    res1 = hpt1.fit(X_working, y_working)\n",
    "    classifiers_dict[clf_name] = hpt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "spread-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91858269, 1.        ]), array([1.        , 0.24471299]), array([0.95756382, 0.39320388]), array([14103,  1655]))\n",
      "(array([0.91612903, 0.65909091]), array([0.99048827, 0.16860465]), array([0.95185862, 0.26851852]), array([1577,  172]))\n",
      "(array([0.93760177, 1.        ]), array([1.        , 0.29713866]), array([0.96779615, 0.4581448 ]), array([14395,  1363]))\n",
      "(array([0.93372434, 0.61363636]), array([0.98943443, 0.19285714]), array([0.96077248, 0.29347826]), array([1609,  140]))\n",
      "(array([0.9998046 , 0.99506173]), array([0.99986972, 0.99261084]), array([0.99983716, 0.99383477]), array([15352,   406]))\n",
      "(array([0.98416422, 0.09090909]), array([0.97671711, 0.12903226]), array([0.98042653, 0.10666667]), array([1718,   31]))\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf1 in classifiers_dict.items():\n",
    "    for X1, y1 in train_test_tuples:\n",
    "        print(sklearn.metrics.precision_recall_fscore_support(clf1.predict(X1), y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "patent-lighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622356495468278\n",
      "0.5795464600138621\n",
      "0.6485693323550991\n",
      "0.5911457870904733\n",
      "0.9962402806264552\n",
      "0.5528746854932592\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf1 in classifiers_dict.items():\n",
    "    for X1, y1 in train_test_tuples:\n",
    "        print(sklearn.metrics.balanced_accuracy_score(clf1.predict(X1), y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ancient-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    15353\n",
       "True       405\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_working['rotors_present'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "federal-curve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1705\n",
       "True       44\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['rotors_present'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "minus-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14103     0]\n",
      " [ 1250   405]]\n",
      "[[1562   15]\n",
      " [ 143   29]]\n",
      "[[14395     0]\n",
      " [  958   405]]\n",
      "[[1592   17]\n",
      " [ 113   27]]\n",
      "[[15350     2]\n",
      " [    3   403]]\n",
      "[[1678   40]\n",
      " [  27    4]]\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf1 in classifiers_dict.items():\n",
    "    for X1, y1 in train_test_tuples:\n",
    "        print(sklearn.metrics.confusion_matrix(clf1.predict(X1), y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-longer",
   "metadata": {},
   "source": [
    "In this sort of classification problem, there are 4 sorts of results:\n",
    "* true postive(hits) - should be positive classification and is\n",
    "* true negative - should be negative and is\n",
    "* false negative (miss) - should be classified positive but is classified negative\n",
    "* false positive (false alarm) - should be classified negative but is classified as positive by the algorithm\n",
    "\n",
    "Given less than 100% accuracy, changing parameters can shift results between false negatives and false positive, depending on which is more damaging for how the prediction will be used. If we decide that predicting a rotor that doesn't happen is more costly, we would penalise false positives. If we decide that a rotor event happening when not forecast is more damaging, we penalise false negatives. Tis can be done by optimising for an F-score other F1. F1 balances tese out, but instead one use a different weighting in the F-score formula for one or the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(classifiers_dict['decision_tree'].predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(classifiers_dict['random_forest'].predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-straight",
   "metadata": {},
   "source": [
    "### Resample the data \n",
    "\n",
    "Our yes/no classes for classification are very unbalanced, so we can try doing a naive resampling so we have equal representation fo the two classes in our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acting-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_working_resampled = pandas.concat([\n",
    "    data_working[data_working[target_feature_name] == True].sample(n=int(1e4), replace=True), \n",
    "    data_working[data_working[target_feature_name] == False].sample(n=int(1e4), replace=False),],\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "superb-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_working_resampled = preproc_input(data_working_resampled, preproc_dict)\n",
    "y_working_resampled = preproc_target(data_working_resampled, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "varied-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_res_tuples = [\n",
    "    (X_working_resampled, y_working_resampled),\n",
    "    (X_test, y_test),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifiers_res_dict = {}                    \n",
    "for clf_name, clf_params in classifiers_params.items():\n",
    "    print(clf_name)\n",
    "    clf1 = clf_params['class']()\n",
    "    cv1 = sklearn.model_selection.KFold(n_splits=5, shuffle=True)\n",
    "    hpt1 = sklearn.model_selection.GridSearchCV(clf1, \n",
    "                                                clf_params['opts'],\n",
    "                                                cv=cv1,\n",
    "                                               )\n",
    "    res1 = hpt1.fit(X_working, y_working)\n",
    "    classifiers_dict[clf_name] = hpt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, clf1 in classifiers_res_dict.items():\n",
    "    for X1, y1 in train_test_res_tuples:\n",
    "        print(sklearn.metrics.precision_recall_fscore_support(clf1.predict(X1), y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, clf1 in classifiers_res_dict.items():\n",
    "    for X1, y1 in train_test_res_tuples:\n",
    "        print(sklearn.metrics.balanced_accuracy_score(clf1.predict(X1), y1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, clf1 in classifiers_res_dict.items():\n",
    "    for X1, y1 in train_test_res_tuples:\n",
    "        print(sklearn.metrics.confusion_matrix(clf1.predict(X1), y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-earth",
   "metadata": {},
   "source": [
    "## Further work\n",
    "\n",
    "Improving results\n",
    "* Outer cross-validation loop\n",
    "* visualising the metrics\n",
    "* using an F-score to penalise false positives or false negatives\n",
    " * using that score as the optimisation criteria for the hyper parameter tuning\n",
    " \n",
    "code performance\n",
    "* using dask ML with a dask cluster to running cross validation and hyper parameter tuning in parallel https://ml.dask.org/joblib.html\n",
    "* logging results in ML flow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experimental-current",
   "language": "python",
   "name": "experimental-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
