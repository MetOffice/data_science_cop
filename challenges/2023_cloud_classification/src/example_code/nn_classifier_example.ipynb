{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Starter code for Cloud Classification Challenge\n",
    "\n",
    "This code is designed as starter point for your development. You do not have to use it, but feel free to use it if you do not know where to start.\n",
    "\n",
    "The [Pytorch](https://pytorch.org/) collection of packages is used to define and train the model, and this code is adapted from their [introductory tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "\n",
    "Other machine learning python packages that you may wish to use include [TensorFlow](https://www.tensorflow.org/overview) and [scikit-learn](https://scikit-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SLURM_NTASKS_PER_NODE'] = '1' # set to prevent pytorch_lightning.trainer from breaking\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Dataset for sat images\n",
    "\n",
    "Dataset instance reads in the directory to the images and their labels.\n",
    "The dataloader enables simple iteration over these images when training and testing a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for label data\n",
    "def get_label_dict():\n",
    "    label_dict = {\"Fish\": 0,\n",
    "                  \"Flower\": 1,\n",
    "                  \"Gravel\": 2,\n",
    "                  \"Sugar\": 3}\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "def sat_label_transform(label):\n",
    "    label_dict = get_label_dict()\n",
    "    return label_dict[label]\n",
    "\n",
    "\n",
    "def sat_label_transform_inv(num):\n",
    "    label_dict = get_label_dict()\n",
    "    ret_list = [key for key in label_dict.keys() if label_dict[key]==num]\n",
    "    return ret_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform for images.\n",
    "# Converts to float and scales values to range 0-1.\n",
    "# Normalisation using the mean/std used by AlexNet.\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for loading the satellite image into a Dataset\n",
    "class SatImageDataset(Dataset):\n",
    "    def __init__(self, labels_file, img_dir, transform=img_transform, target_transform=sat_label_transform):\n",
    "        self.img_labels = pd.read_csv(labels_file)[:1000] # TODO: remove, used for testing\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[\"Image\"].iloc[idx])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels[\"Label\"].iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and testing data using instances of the SatImageDataset defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_files_dir = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/train/\"\n",
    "train_files_labels = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/train/train_labels.csv\"\n",
    "\n",
    "# Create train images dataloader\n",
    "train_images = SatImageDataset(labels_file=train_files_labels, img_dir=train_files_dir)\n",
    "train_dataloader = DataLoader(train_images, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test_files_dir = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/test/\"\n",
    "test_files_labels = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/test/test_labels.csv\"\n",
    "\n",
    "# Create test images dataloader\n",
    "test_images = SatImageDataset(labels_file=test_files_labels, img_dir=test_files_dir)\n",
    "test_dataloader = DataLoader(test_images, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network\n",
    "\n",
    "This is a single layer neural network. For more details on the individual layers, and for further options if you wish to create a different model architecture see [the tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n",
    "\n",
    "Note that the input to the layer has size `150528 = 3*224*224`. The input images are 224 * 224 pixels, with 3 RGB channels.\n",
    "\n",
    "The output layer has size 4 which matches the number of cloud categories available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNCloudClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(3 * 224 * 224, 4)\n",
    "        self.test_outputs = []\n",
    "        self.avg_test_acc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Input data\n",
    "\n",
    "        :return: output - mnist digit label for the input image\n",
    "        \"\"\"\n",
    "        batch_size = x.size()[0]\n",
    "\n",
    "        # (b, 1, 224, 224) -> (b, 1*224*224)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # layer 1 (b, 1*224*224) -> (b, 4)\n",
    "        x = self.l1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc = multiclass_accuracy(pred, y, num_classes=4)\n",
    "\n",
    "        # Use the current of PyTorch logger\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs test and computes the accuracy of the model\n",
    "\n",
    "        :param test_batch: Batch data\n",
    "        :param batch_idx: Batch indices\n",
    "\n",
    "        :return: output - Testing accuracy\n",
    "        \"\"\"\n",
    "        x, y = test_batch\n",
    "        output = self.forward(x)\n",
    "        _, y_hat = torch.max(output, dim=1)\n",
    "        test_acc = multiclass_accuracy(y_hat, y, num_classes=4)\n",
    "        self.test_outputs.append(test_acc)\n",
    "        return {\"test_acc\": test_acc}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes average test accuracy score\n",
    "        \"\"\"\n",
    "        self.avg_test_acc = torch.stack(self.test_outputs).mean()\n",
    "        self.log(\"avg_test_acc\", self.avg_test_acc, sync_dist=True)\n",
    "        self.test_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "2023/08/14 15:52:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:351: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.0.5 and 2.0.5 and may not succeed with packages outside this range.\"\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 602 K \n",
      "--------------------------------\n",
      "602 K     Trainable params\n",
      "0         Non-trainable params\n",
      "602 K     Total params\n",
      "2.408     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31104f0153e4f61a536a441f0e3da97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "2023/08/14 15:55:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/h06/meastman/.conda/envs/dscop_cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a4e63cabe646099d19510c7e01782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.testing metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_acc          0.2444826066493988\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "run_id: f58b85a4b8764ad0893caa657c682a16\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '20', 'optimizer_name': 'Adam', 'lr': '0.02', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False', 'maximize': 'False', 'foreach': 'None', 'capturable': 'False', 'differentiable': 'False', 'fused': 'None'}\n",
      "metrics: {'train_loss': 1.2448924779891968, 'train_loss_step': 1.0397207736968994, 'acc': 0.307343989610672, 'acc_step': 0.6666666865348816, 'train_loss_epoch': 1.2448924779891968, 'acc_epoch': 0.307343989610672, 'avg_test_acc': 0.2444826066493988}\n",
      "tags: {'Mode': 'testing'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize our model\n",
    "classifier = NNCloudClassifier()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=20, devices=1, num_nodes=1)\n",
    "\n",
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(classifier, train_dataloader)\n",
    "    trainer.test(classifier, test_dataloader)\n",
    "    mlflow.log_metric('avg_test_acc', classifier.avg_test_acc)\n",
    "\n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-dscop_cloud_class Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-dscop_cloud_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
