{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "future-actor",
   "metadata": {},
   "source": [
    "# Training a neural network in Tensorflow\n",
    "\n",
    "THis notebook demonstrates training a classifier in Tensorflow, which should mirror what has been done in the scikit-learn notebooks. This is based on the training scripts and the Neural Network architecture they contained, created by Cyril Morecrettte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "patient-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime\n",
    "import math\n",
    "import functools\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complete-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaningful-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medical-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surface-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "affecting-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "premium-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.metrics\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subtle-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_data_dir = '/data/users/shaddad/ds_cop/2021_opmet_challenge/ML'\n",
    "root_data_dir = pathlib.Path('/project/informatics_lab/data_science_cop/ML_challenges/2021_opmet_challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "normal-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_output_dir = pathlib.Path('/data/users/shaddad/ds_cop/2021_opmet_challenge/ML/Rotors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-fourth",
   "metadata": {},
   "source": [
    "## Loading Falklands Rotor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lyric-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/project/informatics_lab/data_science_cop/ML_challenges/2021_opmet_challenge/Rotors')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data_dir.joinpath('Rotors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "administrative-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/project/informatics_lab/data_science_cop/ML_challenges/2021_opmet_challenge/Rotors')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_dir = 'Rotors'\n",
    "falklands_data_path = root_data_dir.joinpath(falklands_dir)\n",
    "falklands_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "medical-alexander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/project/informatics_lab/data_science_cop/ML_challenges/2021_opmet_challenge/Rotors/new_training.csv')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_new_training_data_path = falklands_data_path.joinpath( 'new_training.csv')\n",
    "falklands_new_training_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "informed-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTG</th>\n",
       "      <th>air_temp_obs</th>\n",
       "      <th>dewpoint_obs</th>\n",
       "      <th>wind_direction_obs</th>\n",
       "      <th>wind_speed_obs</th>\n",
       "      <th>wind_gust_obs</th>\n",
       "      <th>air_temp_1</th>\n",
       "      <th>air_temp_2</th>\n",
       "      <th>air_temp_3</th>\n",
       "      <th>air_temp_4</th>\n",
       "      <th>...</th>\n",
       "      <th>windspd_18</th>\n",
       "      <th>winddir_19</th>\n",
       "      <th>windspd_19</th>\n",
       "      <th>winddir_20</th>\n",
       "      <th>windspd_20</th>\n",
       "      <th>winddir_21</th>\n",
       "      <th>windspd_21</th>\n",
       "      <th>winddir_22</th>\n",
       "      <th>windspd_22</th>\n",
       "      <th>Rotors 1 is true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2015 00:00</td>\n",
       "      <td>283.9</td>\n",
       "      <td>280.7</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.000</td>\n",
       "      <td>283.625</td>\n",
       "      <td>283.250</td>\n",
       "      <td>282.625</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>341.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>330.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2015 03:00</td>\n",
       "      <td>280.7</td>\n",
       "      <td>279.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>281.500</td>\n",
       "      <td>281.250</td>\n",
       "      <td>280.750</td>\n",
       "      <td>280.250</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>344.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>348.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2015 06:00</td>\n",
       "      <td>279.8</td>\n",
       "      <td>278.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.875</td>\n",
       "      <td>279.625</td>\n",
       "      <td>279.125</td>\n",
       "      <td>278.625</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>358.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2015 09:00</td>\n",
       "      <td>279.9</td>\n",
       "      <td>277.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.625</td>\n",
       "      <td>279.250</td>\n",
       "      <td>278.875</td>\n",
       "      <td>278.250</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/01/2015 12:00</td>\n",
       "      <td>279.9</td>\n",
       "      <td>277.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>279.250</td>\n",
       "      <td>278.875</td>\n",
       "      <td>278.375</td>\n",
       "      <td>277.875</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>273.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>329.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20101</th>\n",
       "      <td>31/12/2020 06:00</td>\n",
       "      <td>276.7</td>\n",
       "      <td>275.5</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.750</td>\n",
       "      <td>277.625</td>\n",
       "      <td>277.500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>223.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>221.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>219.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20102</th>\n",
       "      <td>31/12/2020 09:00</td>\n",
       "      <td>277.9</td>\n",
       "      <td>276.9</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.625</td>\n",
       "      <td>277.875</td>\n",
       "      <td>277.875</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>230.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>230.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>227.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20103</th>\n",
       "      <td>31/12/2020 12:00</td>\n",
       "      <td>283.5</td>\n",
       "      <td>277.1</td>\n",
       "      <td>220.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>281.125</td>\n",
       "      <td>280.625</td>\n",
       "      <td>280.125</td>\n",
       "      <td>279.625</td>\n",
       "      <td>...</td>\n",
       "      <td>10.3</td>\n",
       "      <td>218.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20104</th>\n",
       "      <td>31/12/2020 15:00</td>\n",
       "      <td>286.1</td>\n",
       "      <td>276.9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.625</td>\n",
       "      <td>284.125</td>\n",
       "      <td>283.625</td>\n",
       "      <td>283.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>226.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20105</th>\n",
       "      <td>01/01/2021 00:00</td>\n",
       "      <td>285.1</td>\n",
       "      <td>279.3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-9999999.0</td>\n",
       "      <td>284.250</td>\n",
       "      <td>284.000</td>\n",
       "      <td>283.750</td>\n",
       "      <td>283.250</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>241.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>236.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>232.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>227.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20105 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DTG  air_temp_obs  dewpoint_obs  wind_direction_obs  \\\n",
       "1      01/01/2015 00:00         283.9         280.7               110.0   \n",
       "2      01/01/2015 03:00         280.7         279.7                90.0   \n",
       "3      01/01/2015 06:00         279.8         278.1               100.0   \n",
       "4      01/01/2015 09:00         279.9         277.0               120.0   \n",
       "5      01/01/2015 12:00         279.9         277.4               120.0   \n",
       "...                 ...           ...           ...                 ...   \n",
       "20101  31/12/2020 06:00         276.7         275.5               270.0   \n",
       "20102  31/12/2020 09:00         277.9         276.9               270.0   \n",
       "20103  31/12/2020 12:00         283.5         277.1               220.0   \n",
       "20104  31/12/2020 15:00         286.1         276.9               250.0   \n",
       "20105  01/01/2021 00:00         285.1         279.3               300.0   \n",
       "\n",
       "       wind_speed_obs  wind_gust_obs  air_temp_1  air_temp_2  air_temp_3  \\\n",
       "1                 4.1     -9999999.0     284.000     283.625     283.250   \n",
       "2                 7.7     -9999999.0     281.500     281.250     280.750   \n",
       "3                 7.7     -9999999.0     279.875     279.625     279.125   \n",
       "4                 7.2     -9999999.0     279.625     279.250     278.875   \n",
       "5                 8.7     -9999999.0     279.250     278.875     278.375   \n",
       "...               ...            ...         ...         ...         ...   \n",
       "20101             3.6     -9999999.0     277.875     277.750     277.625   \n",
       "20102             3.1     -9999999.0     277.875     277.625     277.875   \n",
       "20103             3.6     -9999999.0     281.125     280.625     280.125   \n",
       "20104             3.6     -9999999.0     284.625     284.125     283.625   \n",
       "20105             6.2     -9999999.0     284.250     284.000     283.750   \n",
       "\n",
       "       air_temp_4  ...  windspd_18  winddir_19  windspd_19  winddir_20  \\\n",
       "1         282.625  ...         5.8       341.0         6.0       334.0   \n",
       "2         280.250  ...         6.8       344.0         5.3       348.0   \n",
       "3         278.625  ...         6.0       345.0         5.5       358.0   \n",
       "4         278.250  ...         3.1       338.0         3.5       354.0   \n",
       "5         277.875  ...         1.6       273.0         2.0       303.0   \n",
       "...           ...  ...         ...         ...         ...         ...   \n",
       "20101     277.500  ...        12.1       223.0        11.8       221.0   \n",
       "20102     277.875  ...        10.2       230.0        10.8       230.0   \n",
       "20103     279.625  ...        10.3       218.0        11.9       221.0   \n",
       "20104     283.000  ...         9.4       218.0         8.6       212.0   \n",
       "20105     283.250  ...         8.6       241.0        10.2       236.0   \n",
       "\n",
       "       windspd_20  winddir_21  windspd_21  winddir_22  windspd_22  \\\n",
       "1             6.1       330.0         6.0       329.0         5.8   \n",
       "2             3.8       360.0         3.2        12.0         3.5   \n",
       "3             5.0        10.0         4.2        38.0         4.0   \n",
       "4             3.9         9.0         4.4        22.0         4.6   \n",
       "5             2.3       329.0         2.5       338.0         2.4   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "20101        11.4       219.0        11.3       215.0        11.4   \n",
       "20102        11.6       227.0        12.3       222.0        12.0   \n",
       "20103        12.8       222.0        11.9       225.0        10.6   \n",
       "20104         8.3       218.0         8.7       226.0        10.1   \n",
       "20105        10.5       232.0        10.5       227.0        11.3   \n",
       "\n",
       "       Rotors 1 is true  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "...                 ...  \n",
       "20101               NaN  \n",
       "20102               NaN  \n",
       "20103               NaN  \n",
       "20104               NaN  \n",
       "20105               NaN  \n",
       "\n",
       "[20105 rows x 95 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df = pandas.read_csv(falklands_new_training_data_path, header=0).loc[1:,:]\n",
    "falklands_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaged-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "falklands_training_df = falklands_training_df.drop_duplicates(subset='DTG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animated-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17507, 95)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-element",
   "metadata": {},
   "source": [
    "## Preprocess data for training\n",
    "\n",
    "### Specify and create input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "genetic-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_feature_names = [f'air_temp_{i1}' for i1 in range(1,23)]\n",
    "humidity_feature_names = [f'sh_{i1}' for i1 in range(1,23)]\n",
    "wind_direction_feature_names = [f'winddir_{i1}' for i1 in range(1,23)]\n",
    "wind_speed_feature_names = [f'windspd_{i1}' for i1 in range(1,23)]\n",
    "target_feature_name = 'rotors_present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "postal-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_wind(wind_dir_name, wind_speed_name, row1):\n",
    "    return math.cos(math.radians(row1[wind_dir_name])) * row1[wind_speed_name]\n",
    "\n",
    "def get_u_wind(wind_dir_name, wind_speed_name, row1):\n",
    "    return math.sin(math.radians(row1[wind_dir_name])) * row1[wind_speed_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sharp-vaccine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "u_feature_template = 'u_wind_{level_ix}'\n",
    "v_feature_template = 'v_wind_{level_ix}'\n",
    "u_wind_feature_names = []\n",
    "v_wind_features_names = []\n",
    "for wsn1, wdn1 in zip(wind_speed_feature_names, wind_direction_feature_names):\n",
    "    level_ix = int( wsn1.split('_')[1])\n",
    "    u_feature = u_feature_template.format(level_ix=level_ix)\n",
    "    u_wind_feature_names += [u_feature]\n",
    "    falklands_training_df[u_feature_template.format(level_ix=level_ix)] = falklands_training_df.apply(functools.partial(get_u_wind, wdn1, wsn1), axis='columns')\n",
    "    v_feature = v_feature_template.format(level_ix=level_ix)\n",
    "    v_wind_features_names += [v_feature]\n",
    "    falklands_training_df[v_feature_template.format(level_ix=level_ix)] = falklands_training_df.apply(functools.partial(get_v_wind, wdn1, wsn1), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "frank-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "falklands_training_df[target_feature_name] =  falklands_training_df['Rotors 1 is true']\n",
    "falklands_training_df.loc[falklands_training_df[falklands_training_df['Rotors 1 is true'].isna()].index, target_feature_name] = 0.0\n",
    "falklands_training_df[target_feature_name]  = falklands_training_df[target_feature_name] .astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executive-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    17058\n",
       "True       449\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caring-metro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DTG', 'air_temp_obs', 'dewpoint_obs', 'wind_direction_obs',\n",
       "       'wind_speed_obs', 'wind_gust_obs', 'air_temp_1', 'air_temp_2',\n",
       "       'air_temp_3', 'air_temp_4',\n",
       "       ...\n",
       "       'v_wind_18', 'u_wind_19', 'v_wind_19', 'u_wind_20', 'v_wind_20',\n",
       "       'u_wind_21', 'v_wind_21', 'u_wind_22', 'v_wind_22', 'rotors_present'],\n",
       "      dtype='object', length=140)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falklands_training_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-lyric",
   "metadata": {},
   "source": [
    "### Split into traing/validate/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incomplete-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.1\n",
    "validation_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alive-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_no_rotors = sum(falklands_training_df[target_feature_name] == False)\n",
    "num_with_rotors = sum(falklands_training_df[target_feature_name] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acquired-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_rotors = falklands_training_df[falklands_training_df[target_feature_name] == False]\n",
    "data_with_rotors = falklands_training_df[falklands_training_df[target_feature_name] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stainless-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1705\n",
       "True       44\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pandas.concat([data_no_rotors.sample(int(test_fraction * num_no_rotors)), data_with_rotors.sample(int(test_fraction * num_with_rotors))])\n",
    "data_test[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "prescribed-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "falklands_training_df['test_set'] = False\n",
    "falklands_training_df.loc[data_test.index,'test_set'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sonic-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_working = falklands_training_df[falklands_training_df['test_set'] == False]\n",
    "data_working_no_rotors = data_working[data_working[target_feature_name] == False]\n",
    "data_working_with_rotors = data_working[data_working[target_feature_name] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "infrared-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "data_validation = pandas.concat(\n",
    "    [data_working_no_rotors.sample(int(validation_fraction * num_no_rotors)), \n",
    "     data_working_with_rotors.sample(int(validation_fraction * num_with_rotors))])\n",
    "falklands_training_df['validation_set'] = False\n",
    "falklands_training_df.loc[data_validation.index,'validation_set'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "environmental-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1705\n",
       "True       44\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cardiac-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = falklands_training_df[(~falklands_training_df['test_set']) & (~falklands_training_df['validation_set'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "macro-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    13648\n",
       "True       361\n",
       "Name: rotors_present, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[target_feature_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-fancy",
   "metadata": {},
   "source": [
    "# Preprocess data into input for ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "median-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_names = temp_feature_names + humidity_feature_names + u_wind_feature_names + v_wind_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "formal-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dict = {}\n",
    "for if1 in input_feature_names:\n",
    "    scaler1 = sklearn.preprocessing.StandardScaler()\n",
    "    scaler1.fit(data_train[[if1]])\n",
    "    preproc_dict[if1] = scaler1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "prepared-equation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "target_encoder.fit(data_train[[target_feature_name]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-experience",
   "metadata": {},
   "source": [
    "Apply transformation to each input column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "liquid-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_input(data_subset, pp_dict):\n",
    "    return numpy.concatenate([scaler1.transform(data_subset[[if1]]) for if1,scaler1 in pp_dict.items()],axis=1)\n",
    "\n",
    "def preproc_target(data_subset, enc1):\n",
    "     return enc1.transform(data_subset[[target_feature_name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prescribed-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train = preproc_input(data_train, preproc_dict)\n",
    "y_train = preproc_target(data_train, target_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-payroll",
   "metadata": {},
   "source": [
    "create target feature from rotors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "spare-malta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14009,), (14009, 88))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "internal-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_val = preproc_input(data_validation, preproc_dict)\n",
    "y_val = preproc_target(data_validation, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "contemporary-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test = preproc_input(data_test, preproc_dict)\n",
    "y_test = preproc_target(data_test, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "scenic-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_tuples = [\n",
    "    (X_train, y_train),\n",
    "    (X_val, y_val),\n",
    "    (X_test, y_test),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "white-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tf = numpy.concatenate([y_train.reshape((-1,1)), (1 - y_train.reshape((-1,1)))], axis=1).shape\n",
    "y_val_tf = numpy.concatenate([y_val.reshape((-1,1)), (1 - y_val.reshape((-1,1)))], axis=1).shape\n",
    "y_test_tf = numpy.concatenate([y_test.reshape((-1,1)), (1 - y_test.reshape((-1,1)))], axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-empire",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-russian",
   "metadata": {},
   "source": [
    "### Train Nerual Network using Tensorflow Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "israeli-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate=1.0e-4\n",
    "drop_out_rate=0.2\n",
    "n_epochs=200\n",
    "batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "compliant-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 300\n",
    "n_layers = 4\n",
    "nx = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "anonymous-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               26700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 297,901\n",
      "Trainable params: 297,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tensorflow.keras.models.Sequential()\n",
    "model.add(tensorflow.keras.layers.Dropout(drop_out_rate, input_shape=(nx,)))\n",
    "for i in numpy.arange(0,n_layers):\n",
    "    model.add(tensorflow.keras.layers.Dense(n_nodes, activation='relu', kernel_constraint=tensorflow.keras.constraints.max_norm(3)))\n",
    "    model.add(tensorflow.keras.layers.Dropout(drop_out_rate))\n",
    "model.add(tensorflow.keras.layers.Dense(1, activation='softmax'))             # This is the output layer \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cross-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.optimizers.Adam(learning_rate=initial_learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "activated-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='mse', metrics=[tensorflow.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "southwest-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write things out to file (for reading back in later to make predictions).\n",
    "#TODO: write this out in ONNX\n",
    "model_json=model.to_json()\n",
    "model_out_fname = 'rotors_tf_model.json'\n",
    "model_output_path = project_output_dir.joinpath(model_out_fname)\n",
    "with open(model_output_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "contrary-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14009 samples, validate on 1749 samples\n",
      "Epoch 1/200\n",
      "14009/14009 [==============================] - 3s 235us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 2/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 3/200\n",
      "14009/14009 [==============================] - 1s 80us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 4/200\n",
      "14009/14009 [==============================] - 1s 76us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 5/200\n",
      "14009/14009 [==============================] - 1s 83us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 6/200\n",
      "14009/14009 [==============================] - 1s 75us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 7/200\n",
      "14009/14009 [==============================] - 1s 83us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 8/200\n",
      "14009/14009 [==============================] - 1s 91us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 9/200\n",
      "14009/14009 [==============================] - 2s 124us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 10/200\n",
      "14009/14009 [==============================] - 1s 96us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 11/200\n",
      "14009/14009 [==============================] - 1s 82us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 12/200\n",
      "14009/14009 [==============================] - 1s 75us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 13/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 14/200\n",
      "14009/14009 [==============================] - 1s 86us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 15/200\n",
      "14009/14009 [==============================] - 1s 102us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 16/200\n",
      "14009/14009 [==============================] - 1s 82us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 17/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 18/200\n",
      "14009/14009 [==============================] - 1s 74us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 19/200\n",
      "14009/14009 [==============================] - 1s 75us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 20/200\n",
      "14009/14009 [==============================] - 1s 81us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 21/200\n",
      "14009/14009 [==============================] - 1s 90us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 22/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 23/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 24/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 25/200\n",
      "14009/14009 [==============================] - 1s 81us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 26/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 27/200\n",
      "14009/14009 [==============================] - 1s 88us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 28/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 29/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 30/200\n",
      "14009/14009 [==============================] - 1s 53us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 31/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 32/200\n",
      "14009/14009 [==============================] - 1s 53us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 33/200\n",
      "14009/14009 [==============================] - 1s 78us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 34/200\n",
      "14009/14009 [==============================] - 1s 73us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 35/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 36/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 37/200\n",
      "14009/14009 [==============================] - 1s 75us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 38/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 39/200\n",
      "14009/14009 [==============================] - 1s 80us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 40/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 41/200\n",
      "14009/14009 [==============================] - 1s 82us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 42/200\n",
      "14009/14009 [==============================] - 1s 74us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 43/200\n",
      "14009/14009 [==============================] - 1s 83us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 44/200\n",
      "14009/14009 [==============================] - 1s 70us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 45/200\n",
      "14009/14009 [==============================] - 1s 85us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 46/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 47/200\n",
      "14009/14009 [==============================] - 1s 66us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 48/200\n",
      "14009/14009 [==============================] - 1s 86us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 49/200\n",
      "14009/14009 [==============================] - 1s 76us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 50/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 51/200\n",
      "14009/14009 [==============================] - 1s 46us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 52/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 53/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 54/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 55/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 56/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 57/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 58/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 59/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 60/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 61/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 62/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 63/200\n",
      "14009/14009 [==============================] - 1s 46us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 64/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 65/200\n",
      "14009/14009 [==============================] - 1s 43us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 66/200\n",
      "14009/14009 [==============================] - 1s 65us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 67/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 68/200\n",
      "14009/14009 [==============================] - 1s 45us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 69/200\n",
      "14009/14009 [==============================] - 1s 43us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 70/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 71/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 72/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 73/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 74/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 75/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 76/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 77/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 78/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 79/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 80/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 81/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 82/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 83/200\n",
      "14009/14009 [==============================] - 1s 46us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 84/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 85/200\n",
      "14009/14009 [==============================] - 1s 53us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 86/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 87/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 88/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 89/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 90/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 91/200\n",
      "14009/14009 [==============================] - 1s 68us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 92/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 93/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 94/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 95/200\n",
      "14009/14009 [==============================] - 1s 44us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 96/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 97/200\n",
      "14009/14009 [==============================] - 1s 61us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 98/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 99/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 100/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 101/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 102/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 103/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 104/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 105/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 106/200\n",
      "14009/14009 [==============================] - 1s 46us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 107/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 108/200\n",
      "14009/14009 [==============================] - 1s 66us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 109/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 110/200\n",
      "14009/14009 [==============================] - 1s 44us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 111/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 112/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 113/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 114/200\n",
      "14009/14009 [==============================] - 1s 42us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 115/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 116/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 117/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 118/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 119/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 120/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 121/200\n",
      "14009/14009 [==============================] - 1s 77us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 122/200\n",
      "14009/14009 [==============================] - 1s 69us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 123/200\n",
      "14009/14009 [==============================] - 1s 78us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 124/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 125/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 126/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 127/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 128/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 129/200\n",
      "14009/14009 [==============================] - 1s 70us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 130/200\n",
      "14009/14009 [==============================] - 1s 75us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 131/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 132/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 133/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 134/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 135/200\n",
      "14009/14009 [==============================] - 1s 65us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 136/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 137/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 138/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 139/200\n",
      "14009/14009 [==============================] - 1s 46us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 140/200\n",
      "14009/14009 [==============================] - 1s 40us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 141/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 142/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 143/200\n",
      "14009/14009 [==============================] - 1s 50us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 144/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 145/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 146/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 147/200\n",
      "14009/14009 [==============================] - 1s 49us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 148/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 149/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 150/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 151/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 152/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 153/200\n",
      "14009/14009 [==============================] - 1s 48us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 154/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 155/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 156/200\n",
      "14009/14009 [==============================] - 1s 47us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 157/200\n",
      "14009/14009 [==============================] - 1s 62us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 158/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 159/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 160/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 161/200\n",
      "14009/14009 [==============================] - 1s 78us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 162/200\n",
      "14009/14009 [==============================] - 1s 71us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 163/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 164/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 165/200\n",
      "14009/14009 [==============================] - 1s 63us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 166/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 167/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 168/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 169/200\n",
      "14009/14009 [==============================] - 1s 58us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 170/200\n",
      "14009/14009 [==============================] - 1s 69us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 171/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 172/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 173/200\n",
      "14009/14009 [==============================] - 1s 65us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 174/200\n",
      "14009/14009 [==============================] - 1s 55us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 175/200\n",
      "14009/14009 [==============================] - 1s 52us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 176/200\n",
      "14009/14009 [==============================] - 1s 63us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 177/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 178/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 179/200\n",
      "14009/14009 [==============================] - 1s 77us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 180/200\n",
      "14009/14009 [==============================] - 1s 78us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 181/200\n",
      "14009/14009 [==============================] - 1s 72us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 182/200\n",
      "14009/14009 [==============================] - 1s 64us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 183/200\n",
      "14009/14009 [==============================] - 1s 61us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 184/200\n",
      "14009/14009 [==============================] - 1s 66us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 185/200\n",
      "14009/14009 [==============================] - 1s 54us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 186/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 187/200\n",
      "14009/14009 [==============================] - 1s 56us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 188/200\n",
      "14009/14009 [==============================] - 1s 85us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 189/200\n",
      "14009/14009 [==============================] - 1s 101us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 190/200\n",
      "14009/14009 [==============================] - 2s 135us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 191/200\n",
      "14009/14009 [==============================] - 2s 166us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 192/200\n",
      "14009/14009 [==============================] - 2s 142us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 193/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 194/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 195/200\n",
      "14009/14009 [==============================] - 1s 76us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 196/200\n",
      "14009/14009 [==============================] - 1s 60us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 197/200\n",
      "14009/14009 [==============================] - 1s 59us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 198/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 199/200\n",
      "14009/14009 [==============================] - 1s 51us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n",
      "Epoch 200/200\n",
      "14009/14009 [==============================] - 1s 57us/sample - loss: 0.9742 - root_mean_squared_error: 0.9870 - val_loss: 0.9748 - val_root_mean_squared_error: 0.9873\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "history=model.fit(X_train, \n",
    "                  y_train, \n",
    "                  validation_data=(X_val, \n",
    "                                   y_val), \n",
    "                  epochs=n_epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "durable-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]),\n",
       " array([0.        , 0.02576915]),\n",
       " array([0.        , 0.05024356]),\n",
       " array([    0, 14009]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_recall_fscore_support(model.predict(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "liberal-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/environments/experimental/current/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025769148404597046"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.balanced_accuracy_score(model.predict(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "intensive-toolbox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14009, 13648, 0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0],( y_train==0).sum(), (model.predict(X_train)==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-century",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-jungle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-douglas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "industrial-result",
   "metadata": {},
   "source": [
    "### Resample the data \n",
    "\n",
    "Our yes/no classes for classification are very unbalanced, so we can try doing a naive resampling so we have equal representation fo the two classes in our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_resampled = pandas.concat([\n",
    "    data_train[data_train[target_feature_name] == True].sample(n=int(1e4), replace=True), \n",
    "    data_train[data_train[target_feature_name] == False].sample(n=int(1e4), replace=False),],\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled = preproc_input(data_train_resampled, preproc_dict)\n",
    "y_train_resampled = preproc_target(data_train_resampled, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_res_tuples = [\n",
    "    (X_train_resampled, y_train_resampled),\n",
    "    (X_val, y_val),\n",
    "    (X_test, y_test),    \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experimental-current",
   "language": "python",
   "name": "experimental-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
