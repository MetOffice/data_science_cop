{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354c6a58-3c74-402f-9fd3-84c787e81147",
   "metadata": {},
   "source": [
    "# Iris - classification using keras and tensorflow probability\n",
    "*co-created by Stephen Haddad and ChatGPT*\n",
    "\n",
    "\n",
    "aims of notebook\n",
    "* demonstrate use of tensorflow  for probabilistic classification on iris benchmasrk dataset\n",
    "\n",
    "\n",
    "Other benchmasrk datasets might be tried in this or another notebook\n",
    "https://drive.google.com/drive/folders/1FeZ_yLilvmE1qUp2QRv_wGSfAsJroMIW?usp=share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011fe99-5977-40b2-84ac-03bf98a846b3",
   "metadata": {},
   "source": [
    "Explanation from ChatGPT:\n",
    "> In this example, we use Keras to define the variational distribution that approximates the posterior over the parameters of the Gaussian mixture model. The Keras model consists of two hidden layers with dropout regularization and three output layers for the means, scales, and mixture weights of the Gaussian mixture model. We then use TensorFlow Probability's `fit_surrogate_posterior`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b645e4-421d-4232-895a-475bcff0b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f112c90-e221-486a-b6c5-f902b4dcb63d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: tfp.distributions.MixtureSameFamily(\"MixtureSameFamily\", batch_shape=[?], event_shape=[], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m\n\u001b[1;32m     46\u001b[0m data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((iris\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),))\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Create a TensorFlow Probability VI object for variational inference\u001b[39;00m\n\u001b[1;32m     49\u001b[0m vi \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mvi\u001b[38;5;241m.\u001b[39mfit_surrogate_posterior(\n\u001b[1;32m     50\u001b[0m     target_log_prob_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: model_fn()\u001b[38;5;241m.\u001b[39mlog_prob(args),\n\u001b[0;32m---> 51\u001b[0m     surrogate_posterior\u001b[38;5;241m=\u001b[39m\u001b[43mvariational_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     52\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m),\n\u001b[1;32m     53\u001b[0m     num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     54\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Extract the posterior distribution over the parameters of the model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m weights, means, scales \u001b[38;5;241m=\u001b[39m vi\u001b[38;5;241m.\u001b[39msurrogate_posterior\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m, in \u001b[0;36mvariational_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m dist \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMixtureSameFamily(\n\u001b[1;32m     37\u001b[0m     mixture_distribution\u001b[38;5;241m=\u001b[39mtfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mweights),\n\u001b[1;32m     38\u001b[0m     components_distribution\u001b[38;5;241m=\u001b[39mtfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(loc\u001b[38;5;241m=\u001b[39mmeans, scale\u001b[38;5;241m=\u001b[39mscales))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Define the Keras model\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/keras/engine/functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)]):\n\u001b[1;32m    147\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/keras/engine/functional.py:186\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m    184\u001b[0m     base_layer_utils\u001b[38;5;241m.\u001b[39mcreate_keras_history(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_outputs)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_graph_inputs_and_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# built.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/keras/engine/functional.py:740\u001b[0m, in \u001b[0;36mFunctional._validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    739\u001b[0m   cls_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput tensors of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    741\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe output of a TensorFlow `Layer` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    742\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(thus holding past layer metadata). Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: tfp.distributions.MixtureSameFamily(\"MixtureSameFamily\", batch_shape=[?], event_shape=[], dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the Iris dataset\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                   header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "iris = iris.drop(columns='species')\n",
    "\n",
    "# Define a probabilistic model using TensorFlow Probability\n",
    "def model_fn():\n",
    "    # Priors over the parameters of a Gaussian mixture model\n",
    "    weights = tfp.layers.DenseFlipout(3, activation='softmax', name='weights')(tf.zeros((1, 4)))\n",
    "    means = tfp.layers.DenseFlipout(3, name='means')(tf.zeros((1, 4)))\n",
    "    scales = tfp.layers.DenseFlipout(3, activation='softplus', name='scales')(tf.zeros((1, 4)))\n",
    "\n",
    "    # Mixture components\n",
    "    dist = tfp.distributions.MixtureSameFamily(\n",
    "        mixture_distribution=tfp.distributions.Categorical(probs=weights),\n",
    "        components_distribution=tfp.distributions.Normal(loc=means, scale=scales))\n",
    "    return dist\n",
    "\n",
    "# Define a Keras model for the variational distribution using TensorFlow Probability\n",
    "def variational_fn():\n",
    "    # Inputs to the model\n",
    "    inputs = tf.keras.layers.Input(shape=(4,))\n",
    "\n",
    "    # Hidden layers with dropout regularization\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Outputs of the model\n",
    "    weights = tf.keras.layers.Dense(3, activation='softmax', name='weights')(x)\n",
    "    means = tf.keras.layers.Dense(3, name='means')(x)\n",
    "    scales = tf.keras.layers.Dense(3, activation='softplus', name='scales')(x)\n",
    "\n",
    "    # Create a distribution from the outputs\n",
    "    dist = tfp.distributions.MixtureSameFamily(\n",
    "        mixture_distribution=tfp.distributions.Categorical(probs=weights),\n",
    "        components_distribution=tfp.distributions.Normal(loc=means, scale=scales))\n",
    "\n",
    "    # Define the Keras model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=dist)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a TensorFlow Dataset object for the Iris data\n",
    "data = tf.data.Dataset.from_tensor_slices((iris.values.astype(np.float32),))\n",
    "\n",
    "# Create a TensorFlow Probability VI object for variational inference\n",
    "vi = tfp.vi.fit_surrogate_posterior(\n",
    "    target_log_prob_fn=lambda *args: model_fn().log_prob(args),\n",
    "    surrogate_posterior=variational_fn(),\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "    num_steps=1000,\n",
    "    dataset=data)\n",
    "\n",
    "# Extract the posterior distribution over the parameters of the model\n",
    "weights, means, scales = vi.surrogate_posterior.sample(1000).numpy().mean(axis=0)\n",
    "\n",
    "# Print the results\n",
    "print('Inferred weights:', weights)\n",
    "print('Inferred means:', means)\n",
    "print('Inferred scales:', scales)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
