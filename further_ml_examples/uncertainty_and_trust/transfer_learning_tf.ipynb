{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bcb637-135f-4e9c-9f32-0329f1330109",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transfer learning tutorial\n",
    "\n",
    "Based on code from https://keras.io/guides/transfer_learning/\n",
    "Python available here: https://github.com/keras-team/keras-io/blob/master/guides/transfer_learning.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d190032-cf3c-4c4c-aa0d-17ee4460d561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db34e9-2141-425d-be94-74c36a036df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637afe8c-9b07-4acd-a487-092931fe57cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4401d-8d04-44de-b649-93bfc6584966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b2c41-bc1a-4b2c-a523-5601ef678f1f",
   "metadata": {},
   "source": [
    "Demonstrating trainable vs non-trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f8cc5-ce8d-4aed-87cb-6d69d3660e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build((None, 4))  # Create the weights\n",
    "\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652e794-080b-4a0f-abbd-663d285ad105",
   "metadata": {},
   "source": [
    "setting layer to non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda1757-be3f-41d4-b50d-1f6a5630819c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "layer.trainable = False  # Freeze the layer\n",
    "\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fb60e-ca10-4dab-9973-ad503f0b7520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9f3e8-b837-4323-8424-95e1d7c4d1b9",
   "metadata": {},
   "source": [
    "demonstrating that layer weights dont change during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66777e4-737e-413e-ae17-af789d0b8356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a model with 2 layers\n",
    "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
    "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
    "model = keras.Sequential([tensorflow.keras.Input(shape=(3,)), layer1, layer2])\n",
    "\n",
    "# Freeze the first layer\n",
    "layer1.trainable = False\n",
    "\n",
    "# Keep a copy of the weights of layer1 for later reference\n",
    "initial_layer1_weights_values = layer1.get_weights()\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
    "\n",
    "# Check that the weights of layer1 have not changed during training\n",
    "final_layer1_weights_values = layer1.get_weights()\n",
    "np.testing.assert_allclose(\n",
    "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
    ")\n",
    "np.testing.assert_allclose(\n",
    "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92156bd1-f562-4d45-973f-cdfd46bc8167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inner_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(3,)),\n",
    "        keras.layers.Dense(3, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [keras.Input(shape=(3,)), \n",
    "     inner_model, \n",
    "     keras.layers.Dense(3, activation=\"sigmoid\"),]\n",
    ")\n",
    "\n",
    "model.trainable = False  # Freeze the outer model\n",
    "\n",
    "assert inner_model.trainable == False  # All layers in `model` are now frozen\n",
    "assert inner_model.layers[0].trainable == False  # `trainable` is propagated recursively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c21231-f665-4f16-b667-f09756a26208",
   "metadata": {},
   "source": [
    "# Two transfer learning approaches\n",
    "\n",
    "The usual transfer learning workflow is summarised as follows:\n",
    "* Instantiate a base model and load pre-trained weights into it.\n",
    "* Freeze all layers in the base model by setting trainable = False.\n",
    "* Create a new model on top of the output of one (or several) layers from the base model.\n",
    "* Train your new model on your new dataset.\n",
    "* optional - fine tune model bhy unfreezing weights and running training with new data\n",
    "\n",
    "Note that an alternative, more lightweight workflow could also be:\n",
    "1. Instantiate a base model and load pre-trained weights into it.\n",
    "1. Run your new dataset through it and record the output of one (or several) layers from the base model. This is called feature extraction.\n",
    "1.  Use that output as input data for a new, smaller model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc04fd1-56ea-4891-bd37-c4dfac1beb20",
   "metadata": {},
   "source": [
    "basic transfer learning workflow demo, demonstrating the four steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230ba23-7bee-4721-8993-504c6113f8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf8d0a-4494-4fe1-872a-84be1e12031e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abc54d-f7d3-4835-a10d-ad1400c5636d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae99989-0010-4125-bde1-65d048c21352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb7fd9-ad0b-455c-bbfa-41ca57820bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if we had an additional image dataset to train on, we would then use it here as follows\n",
    "# model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f3e76-25ab-49c9-bbb3-44bd38376f00",
   "metadata": {},
   "source": [
    "Once we have trained the new layers, we may wish to fine tune the whole model with the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d599823-764f-414c-9ec2-2d6748790caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# It's important to recompile your model after you make any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are take into account\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd58d6c-d01d-455a-bfed-69cb383c776f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train end-to-end. Be careful to stop before you overfit!\n",
    "## model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a6d23-168c-4435-9c0d-61ce4a58168d",
   "metadata": {},
   "source": [
    "#### Cstuom training loop\n",
    "\n",
    "In more specialised, you may use a custom training loop rather than the standard `model.fit()` call. Transfer learning can easily be done in a custom traiining loop where required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2c018-172e-4584-bf02-5bc3eab14d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create base model\n",
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e749c-ac15-4260-a4d7-62f50ff3158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new model on top.\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b16a5-a713-42dc-928d-39533c08aae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772d20b-8bba-4361-9043-3f402c25b54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.input, model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a67ee7-a483-4edc-8b72-0d2aa7c8431b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over the batches of a dataset.\n",
    "for inputs, targets in validation_ds:\n",
    "    # Open a GradientTape.\n",
    "    with tensorflow.GradientTape() as tape:\n",
    "        # Forward pass.\n",
    "        predictions = model(inputs)\n",
    "        # Compute the loss value for this batch.\n",
    "        loss_value = loss_fn(targets, predictions)\n",
    "\n",
    "    # Get gradients of loss wrt the *trainable* weights.\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    # Update the weights of the model.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1dd68-229b-4ff4-8ae7-00daf7e79650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transfer learning example - cats vs dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb933e44-0e02-4109-a25a-cf49d82a900a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    # Reserve 10% for validation and 10% for test}\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7a3fd-2e5e-4115-b887-0870fb88c40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of training samples: %d\" % tensorflow.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of validation samples: %d\" % tensorflow.data.experimental.cardinality(validation_ds))\n",
    "print(\"Number of test samples: %d\" % tensorflow.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30da8de-e1fa-421e-8e43-6a9dd247eff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f22ab-66f9-4e51-9097-b05932fc5b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = (150, 150)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tensorflow.image.resize(x, size), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (tensorflow.image.resize(x, size), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tensorflow.image.resize(x, size), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea8584-4ee8-4787-8f8a-aede1d5369b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ef7f7-a282-4874-8e90-5fdee5844f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds_batch = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds_batch = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds_batch = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73019025-6bba-414c-bec1-cddab50f6fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [keras.layers.RandomFlip(\"horizontal\"), \n",
    "     keras.layers.RandomRotation(0.1),]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62db55-aae6-4463-9aca-710a0e87742b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a81623-28ba-4428-8ad7-8083f4616c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = image\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tensorflow.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(label))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879329de-f397-49d3-97ac-028b92625dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6164f12-f603-4f67-8a57-399280133d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1c42c-ad5d-46f3-bbbc-0077c34e5801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the base_model\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478bd3c-fa27-4f41-a992-160c78219d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "# x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd02d13-2611-41f1-9406-e18391ed3cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc39b7-91c7-466e-a68d-c5d8639a5b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c832c-5bcc-432f-ad1d-e0bec6312d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(1)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdc527-28f9-4d3a-92f1-3cfd4900f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17f4ff-19b1-4bbc-b4ac-32272dab4659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbbc0e-730e-4468-9edb-15f45e5bd270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81787c21-fe37-497d-8fa6-dd3c101e4b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c6e55-6f8c-4bc8-96e3-0ed1803300b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317665-5894-463a-95e0-ff06e2f0c11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f221b68-0e65-4696-af50-0f253b58debc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68803a4a-ad60-4a7c-9131-e4a6b4bb4fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# recompile the model after changing some parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef9a29-1eb5-41c6-8539-c96e6e668345",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
