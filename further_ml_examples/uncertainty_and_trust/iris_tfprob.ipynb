{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf268a52-5fc3-4091-9881-2a959db685c2",
   "metadata": {},
   "source": [
    "# Exploring probabilistic modelling - Tensorflow probability and Iris dataset\n",
    "\n",
    "* co-created by Stepohen Haddad and ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f4ebb9-289e-4d9c-bf87-89806081328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643bcec8-aaf5-4f14-8ba0-b317832c8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Iris dataset\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                   header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "iris = iris.drop(columns='species')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35508b33-65df-492b-a346-ab7d0a1d3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a probabilistic model using TensorFlow Probability\n",
    "def model_fn():\n",
    "    # Priors over the parameters of a Gaussian mixture model\n",
    "    weights = tfp.layers.DenseFlipout(3, activation='softmax', name='weights')(tf.zeros((1, 4)))\n",
    "    means = tfp.layers.DenseFlipout(3, name='means')(tf.zeros((1, 4)))\n",
    "    scales = tfp.layers.DenseFlipout(3, activation='softplus', name='scales')(tf.zeros((1, 4)))\n",
    "\n",
    "    # Mixture components\n",
    "    dist = tfp.distributions.MixtureSameFamily(\n",
    "        mixture_distribution=tfp.distributions.Categorical(probs=weights),\n",
    "        components_distribution=tfp.distributions.Normal(loc=means, scale=scales))\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d1c5b0-1522-49be-88d4-62628b383438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a variational distribution using TensorFlow Probability\n",
    "def variational_fn():\n",
    "    # Approximate posterior over the parameters of the Gaussian mixture model\n",
    "    weights = tfp.layers.VariableLayer(1, dtype=tf.float32, name='weights')\n",
    "    means = tfp.layers.VariableLayer(1, dtype=tf.float32, name='means')\n",
    "    scales = tfp.layers.VariableLayer(1, dtype=tf.float32, name='scales')\n",
    "    return tfp.distributions.MixtureSameFamily(\n",
    "        mixture_distribution=tfp.distributions.Categorical(probs=weights),\n",
    "        components_distribution=tfp.distributions.Normal(loc=means, scale=scales))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfbc81d-aafd-4ad9-9802-f48f230b27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow Dataset object for the Iris data\n",
    "data = tf.data.Dataset.from_tensor_slices((iris.values.astype(np.float32),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a8e7f9-606f-4ac0-b16b-59ec0a7917fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<tensorflow_probability.python.layers.variable_input.VariableLayer object at 0x7fb96273bd00>) with an unsupported type (<class 'tensorflow_probability.python.layers.variable_input.VariableLayer'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a TensorFlow Probability VI object for variational inference\u001b[39;00m\n\u001b[1;32m      2\u001b[0m vi \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mvi\u001b[38;5;241m.\u001b[39mfit_surrogate_posterior(\n\u001b[1;32m      3\u001b[0m     target_log_prob_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: model_fn()\u001b[38;5;241m.\u001b[39mlog_prob(args),\n\u001b[0;32m----> 4\u001b[0m     surrogate_posterior\u001b[38;5;241m=\u001b[39m\u001b[43mvariational_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m),\n\u001b[1;32m      6\u001b[0m     num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      7\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdata)\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mvariational_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m means \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mVariableLayer(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m scales \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mVariableLayer(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscales\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMixtureSameFamily(\n\u001b[0;32m----> 8\u001b[0m     mixture_distribution\u001b[38;5;241m=\u001b[39m\u001b[43mtfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      9\u001b[0m     components_distribution\u001b[38;5;241m=\u001b[39mtfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(loc\u001b[38;5;241m=\u001b[39mmeans, scale\u001b[38;5;241m=\u001b[39mscales))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:342\u001b[0m, in \u001b[0;36m_DistributionMeta.__new__.<locals>.wrapped_init\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to have things set in `self` before `__init__` is\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# called, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m \u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to override things set in `self` by subclass\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# `__init__`, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;66;03m# We prefer subclasses will set `parameters = dict(locals())` because\u001b[39;00m\n\u001b[1;32m    347\u001b[0m   \u001b[38;5;66;03m# this has nearly zero overhead. However, failing to do this, we will\u001b[39;00m\n\u001b[1;32m    348\u001b[0m   \u001b[38;5;66;03m# resolve the input arguments dynamically and only when needed.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow_probability/python/distributions/categorical.py:191\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, logits, probs, dtype, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[1;32m    190\u001b[0m   prob_logit_dtype \u001b[38;5;241m=\u001b[39m dtype_util\u001b[38;5;241m.\u001b[39mcommon_dtype([probs, logits], tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 191\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_nonref_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprob_logit_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logits \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(\n\u001b[1;32m    194\u001b[0m       logits, dtype_hint\u001b[38;5;241m=\u001b[39mprob_logit_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28msuper\u001b[39m(Categorical, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    196\u001b[0m       dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    197\u001b[0m       reparameterization_type\u001b[38;5;241m=\u001b[39mreparameterization\u001b[38;5;241m.\u001b[39mNOT_REPARAMETERIZED,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m       parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    201\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow_probability/python/internal/tensor_util.py:119\u001b[0m, in \u001b[0;36mconvert_nonref_to_tensor\u001b[0;34m(value, dtype, dtype_hint, as_shape_tensor, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_shape_tensor:\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m prefer_static\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m    118\u001b[0m       value, dtype\u001b[38;5;241m=\u001b[39mdtype, dtype_hint\u001b[38;5;241m=\u001b[39mdtype_hint, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pip-tfprob/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow_probability.python.layers.variable_input.VariableLayer object at 0x7fb96273bd00>) with an unsupported type (<class 'tensorflow_probability.python.layers.variable_input.VariableLayer'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a TensorFlow Probability VI object for variational inference\n",
    "vi = tfp.vi.fit_surrogate_posterior(\n",
    "    target_log_prob_fn=lambda *args: model_fn().log_prob(args),\n",
    "    surrogate_posterior=variational_fn(),\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "    num_steps=1000,\n",
    "    dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9a233-6af5-482e-bd5c-f42d2c225513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the posterior distribution over the parameters of the model\n",
    "weights, means, scales = vi.surrogate_posterior.sample(1000).numpy().mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652fed2-3924-49de-bda6-fc1bb0df7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print the results\n",
    "print('Inferred weights:', weights)\n",
    "print('Inferred means:', means)\n",
    "print('Inferred scales:', scales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a47c4-8d6f-45d3-a0c4-11aa8a0871dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ecb68-efad-4e21-b295-c52c184f564b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c4ca2-7121-4245-b920-04b9fa933ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b0447-2a4f-477e-9e92-c5c080753e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82777a42-bfdc-45f5-986f-c5a4a23bf7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
