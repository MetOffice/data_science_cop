{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/data_models.png width=1000/>\n",
    "\n",
    "## Python Data Science Tools - Data Models\n",
    "\n",
    "**What are data models and why are they useful?**\n",
    "\n",
    "\"*A data model is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.*\" - Wikipedia\n",
    "\n",
    "Basically, a data model holds data in an object that is easier and more convenient to use than raw 1s and 0s. This can include a way to store metadata with the the data, displaying the data through interfaces that make it easier to understand and automatically perfoming functions for us that would otherwise require a lot of engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data - Python\n",
    "\n",
    "Python has a number of basic data structures that allow us to store data in the memory of the computer:\n",
    "\n",
    "- [Lists] = Mutable series of data\n",
    "- (Tuples) = Immutable series of data\n",
    "- {Dict:onaries} = Key:Value pairs\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [279.3, 284.0, 290.1, 284.1]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = ('Wales', 'Scotland', 'England', 'Northern Ireland')\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'foo': 7, 'bar': 'Closed'}\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these data structures contain data but without context, do we know enough about what these values are? <br>Is `lst` a list of temperature values or latitude coordinates? Is `tup` an immutable list of nations or names of the childeren in an unfortunate family?\n",
    "\n",
    "**Without metadata and some mapping of how the values relate to one another, the data is not very useful to us.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Data - Pandas\n",
    "\n",
    "**References:<br>Pandas documentaiton -> https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html**\n",
    "\n",
    "All of us will be familiar with tabular data - values arranged into rows and columns to convey relations between data.\n",
    "\n",
    "|Name|Age|Height|\n",
    "|---|---|---|\n",
    "|Alice|28|1.86|\n",
    "|Bob|26|1.75|\n",
    "|Charlie|99|1.83|\n",
    "\n",
    "We may be familiar with tools that allow us to work with tabular data, such as Excel, MATLAB, databases (MongoDB, SQL), or pen & paper.\n",
    "\n",
    "A Python data structure we could use to represent a table is a dictionary, where the `keys` are the column labels and the `values` are a list of the values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'Name':  ['Alice', 'Bob', 'Charlie'],\n",
    "         'Age':   [28, 26, 99],\n",
    "         'Height':[1.86, 1.75, 1.83]}\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a perfectly correct way to store the data containted in a table, but is not particularly useful for interacting with the data in ways we expect to for tabular data. \n",
    "\n",
    "For instance, selecting a row from the table represented with the dictionary is not simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = [table['Name'][1],\n",
    "        table['Age'][1],\n",
    "        table['Height'][1]]\n",
    "\n",
    "row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit cumbersome and for a table with 20 columns would get frustrating and messy.\n",
    "\n",
    "So we could implement a function to get a row for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(i, table):\n",
    "    row = []\n",
    "    for key in table.keys():\n",
    "        row.append(table[key][i])\n",
    "    return row\n",
    "\n",
    "get_row(1, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works and will scale to a table with 20 columns just fine, but it involved engineering and I'm lazy so don't want to engineer every feature of a table when I need it.\n",
    "\n",
    "Thankfully [Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) is a Python library which allows us to work with tabular data using a data model called a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html?highlight=dataframe#pandas.DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we can see that this is a much more familiar model for intarcting with tabular data than a dictionary. On top of being pretty, Pandas has implemented a whole spectrum of features and functionality that makes working with tabular data more simple and powerful*.\n",
    "\n",
    "_*Pandas is underpinned with some very fast C code, which leads to operations on huge tables of data running at lightning speed._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can we do with a Pandas DataFrame?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing rows and columns\n",
    "\n",
    "This is easy with a DataFrame and fundamental to interacting with it. We can select columns or rows either by index or values, in a number of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can be indexed like a Python dictionary\n",
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But columns are also attributes of the DataFrame object\n",
    "df.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows can be retrieved by index using iloc[]\n",
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or retrieved by index value using loc[] (which in this case returns the same as iloc[])\n",
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows can also be selected based on their values\n",
    "df.loc[df.Name == 'Bob']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the table is currently an integer, but we can set the index of the table to whatever we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = df.set_index('Name')\n",
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have changed the index, we can use loc[] to get a row based on a Name value\n",
    "df_name.loc['Bob']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort rows\n",
    "\n",
    "Pandas also gives us the power to sort a DataFrame into orders that are easier to work with. The table is already sorted in alphabetical order for names, but we can also order it according to index, heights or age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort according to index, including in reverse order\n",
    "df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also sort by the values of any column\n",
    "df.sort_values(by=\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And of course reverse the order\n",
    "df.sort_values(by=\"Height\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats\n",
    "\n",
    "Pandas includes makes it easy to perform statistical operations on DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of all the columns\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend\n",
    "\n",
    "Pandas makes it easy to extent DataFrames by adding columns, concatenating or merging them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = {'Name': ['Daniel', 'Evan', 'Fred'],\n",
    "          'Age': [43, 15, 31], \n",
    "          'Height': [1.53, 1.89, 1.56]}\n",
    "\n",
    "df2 = pd.DataFrame(table2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easy to concatenate DataFrames\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to reset the indices when concatenating\n",
    "pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also easy to add a new column to a DataFrame with insert()\n",
    "df2.insert(loc=2, column='Weight', value=[89, 71, 74])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas also supports database style merge() operations\n",
    "df.merge(df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot\n",
    "\n",
    "Finally, Pandas also includes some quick plotting functionality to make it easy to visualise your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot() method supports many kinds of plots\n",
    "df.plot(x='Name', y='Height', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much much more to Pandas. Please see [list of example notebooks](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks#pandas-for-data-analysis) and [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridded Data - Numpy\n",
    "**References:<br>Numpy documentaiton -> https://numpy.org/doc/stable/user/quickstart.html**\n",
    "\n",
    "All of us will also be familiar with gridded data - an array of values arranged on an n-dimensional grid.\n",
    "\n",
    "![](further_ds_examples/iris_course/images/multi_array.png)\n",
    "\n",
    "We can technically use a table to represent an array, or a list of lists, but these solutions are clunky and difficult to use.\n",
    "\n",
    "Instead we use Numpy to create n-dimensional array that we can interact with similar to mathematical matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random(size=(4, 3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing values from an array uses matrix notation\n",
    "arr[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which you can use to set values\n",
    "arr[2,1] = 2\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also perform maths with arrays\n",
    "arr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And statistics\n",
    "arr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have no idea what these data values represent - **A Numpy array contains no metadata.**\n",
    "\n",
    "There is much much more to Numpy. Please see the [Numpy notebook](further_ds_examples/numpy_intro.ipynb) in `further_ds_examples` and the [docs](https://numpy.org/doc/stable/user/quickstart.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridded Data - Iris\n",
    "\n",
    "Many of us at the Met Office will have used Iris at some point. Iris gives us arrays with metadata using the CF (Climate-Forecast) data model:\n",
    "\n",
    "![](further_ds_examples/iris_course/images/multi_array_to_cube.png)\n",
    "\n",
    "Iris wraps a numpy array with metadata into an object called a `Cube`. This has clearer interface to understand what all the axes of the n-dimensional array represent, what the values represent and other arbitrary metadata such as how the data was produced.\n",
    "\n",
    "Multiple `Cube`s can also be collated together in a `CubeList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cube from the Numpy array we made before\n",
    "import iris\n",
    "\n",
    "cube = iris.cube.Cube(data=arr)\n",
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can still access the array\n",
    "cube.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's name the cube and give it units\n",
    "cube.standard_name = 'air_temperature'\n",
    "cube.units = 'Â°C'\n",
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add dimension coordinates to describe the axes of the array\n",
    "lon = iris.coords.DimCoord([-180, -90, 0, 90], standard_name='longitude', units='degrees')\n",
    "lat = iris.coords.DimCoord([-45, 0, 45], standard_name='latitude', units='degrees')\n",
    "\n",
    "cube.add_dim_coord(lon, 0)\n",
    "cube.add_dim_coord(lat, 1)\n",
    "\n",
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can store multiple Cubes in a CubeList\n",
    "cube2 = cube\n",
    "cubes = iris.cube.CubeList([cube, cube2])\n",
    "cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like the array, we can perform maths on a cube\n",
    "cube_K = cube + 273\n",
    "display(cube_K)\n",
    "display(cube_K.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And statistics\n",
    "cube_mean = cube.collapsed(coords=['longitude', 'latitude'], aggregator=iris.analysis.MEAN)\n",
    "display(cube_mean)\n",
    "display(cube_mean.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris also has a quickplot function to easily plot Cubes\n",
    "import iris.quickplot as qplt\n",
    "%matplotlib inline\n",
    "\n",
    "qplt.contourf(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With some help from matplotlib we can add coastlines\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "qplt.contourf(cube)\n",
    "plt.gca().coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much much more to Iris. Please see the [Iris course notebooks](further_ds_examples/iris_course/0.Iris_Course_Intro.ipynb) in `further_ds_examples` and the [docs](https://scitools.org.uk/iris/docs/latest/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridded Data - Xarray\n",
    "\n",
    "- netCDF data model\n",
    "- DataArray == Cube\n",
    "- DataSet ~= CubeDict\n",
    "- Less strict with metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-science-cop)",
   "language": "python",
   "name": "data-science-cop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
